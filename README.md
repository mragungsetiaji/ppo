# PPO: Proximal Policy Optimization

## Pseudocode
![ppo](https://spinningup.openai.com/en/latest/_images/math/e62a8971472597f4b014c2da064f636ffe365ba3.svg)


## Installation:
---
```bash
poetry install
poetry shell
```

## How to run:
---
```bash
python main.py
```

## Environments:
---
Note that in this PPO implementation, you can only use the ones with Box for both observation and action spaces.

Hyperparameters can be found here. https://github.com/araffin/rl-baselines-zoo/blob/master/hyperparams/ppo2.yml

## References:
https://github.com/ericyangyu/PPO-for-Beginners